---
title: "practice_1"
output: pdf_document
---

```{r}
#Problem 1

#Importing Libraries
library(data.table)

#Importing Data
cust_data <- read.csv('customertxndata.csv')
setDT(cust_data)

#Total Revenue
sum_revenue <- cust_data[,na.omit(sum(revenue))]
sprintf("total transaction amount: %s", sum_revenue)

#Mean Visits
mean_visits <- cust_data[,na.omit(mean(visits))]
sprintf("mean number of visits: %s", mean_visits)

#Mean Revenue
median_revenue <- cust_data[,na.omit(median(revenue))]
sprintf("median revenue: %s", median_revenue)

#Median Revenue
SD_revenue <- cust_data[,na.omit(sd(revenue))]
sprintf("standard deviation of revenue: %s", SD_revenue)

#Most Common Gender
gender_count <- cust_data[,.(count = .N), by = "gender"][order(-count)]
gender_count
sprintf("most common gender is %s", gender_count[1,1])
```


```{r}
#Problem 2
library("ggplot2")

#Total revenue by gender
revenue_by_gender <- cust_data[, sum(revenue), by = gender]
revenue_by_gender <- na.omit(revenue_by_gender)

#Bar chart 
ggplot(data=revenue_by_gender, aes(x=gender, y=V1)) +
  geom_bar(stat="identity", fill="steelblue", width = 0.5) +
  xlab("Gender") + ylab("Revenue")
```


```{r}
#Problem 3
library("ggpubr")

#Pearson Moment of Correlation between number of visits and revenue
ggscatter(cust_data, x = "visits", y = "revenue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Number of visits", ylab = "Revenue generated") +
  geom_smooth(method = 'gam', formula = y ~ s(x, bs = "cs"))
```


```{r}
#Problem 4
library(tidyverse)

#creating a table containing only the NA values
missing_data <- cust_data %>% filter_all(any_vars(is.na(.)))

#rows having missing data
missing_data

#Every column has missing data, and 7,200 rows have missing values.
#We can impute the missing values by the mean of the column, and for columns having outliers we must ignore them before calculating the mean.
```


```{r}
#Problem 5

#Mean transactions
clean_cust_data <- na.omit(cust_data)

#Calculating mean for transactions
clean_cust_data[, round(mean(transactions))]

#Assigning mean value to NA in transactions column
impute_trans <- cust_data
impute_trans[is.na(cust_data$transactions)] <- 1

#Creating function for mode
getmode <- function(v) 
  {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
  }

#Mode of gender
cust_data[, getmode(gender)]

#Assigning mode value to NA in gender column
impute_gender <- cust_data
impute_gender[is.na(cust_data$gender)] <- "Male"
```


```{r}
#Problem 6

#Spliting the data into a trainig and validation dataset 
training_data <- cust_data[rep(c(TRUE,FALSE), length = .N), ]     #logical vector c(TRUE,FALSE) will only return 1st,3rd,5th...values
validation_data <- cust_data[rep(c(FALSE,TRUE), length = .N), ]   #logical vector c(FALSE,TRUE) will only return 2nd,4th,6th...values
```


```{r}
#Problem 7

#Calculating mean revenue for trainig dataset
mean_train <- training_data[,na.exclude(mean(revenue))]
sprintf("mean of training data: %s", mean_train)

#Calculating mean revenue for validation dataset
mean_val <- validation_data[,na.exclude(mean(revenue))]
sprintf("mean of validation data: %s", mean_val)
```


```{r}
#Problem 8
set.seed(77654)

#Creating first sample to set 60% of data for training
sample_1 <- sample.int(n = nrow(cust_data), size = floor(.60*nrow(cust_data)), replace = F)

#Creating dataset for training
training <- cust_data[sample_1,]

#Creating a dataset of the remaining data for testing and validation
remaining_data <- cust_data[-sample_1,]

#Creating second sample to split the reamining dataset for testing and validation
sample_2 <- sample.int(n = nrow(remaining_data), size = floor(.50*nrow(remaining_data)), replace = F)

#Creating dataset for testing
testing <- remaining_data[sample_2, ]

#Creating dataset for validation
validation <- remaining_data[-sample_2, ]
```

